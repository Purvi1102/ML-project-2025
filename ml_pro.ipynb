{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d3deb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[âœ”] CSV created with 4657 entries at: synthetic_expiry_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ğŸ“‚ Folder where images are stored (adjust if needed)\n",
    "image_root = \"images\"\n",
    "\n",
    "# âœ… Write the CSV in the current directory (ML_project/)\n",
    "output_csv = \"synthetic_expiry_labels.csv\"\n",
    "\n",
    "# ğŸ·ï¸ Generate expiry date and class\n",
    "def generate_expiry_info():\n",
    "    today = datetime.today()\n",
    "    days_to_expiry = random.randint(-15, 60)\n",
    "    expiry_date = today + timedelta(days=days_to_expiry)\n",
    "\n",
    "    if days_to_expiry < 0:\n",
    "        label = \"expired\"\n",
    "    elif days_to_expiry <= 15:\n",
    "        label = \"expiring_soon\"\n",
    "    else:\n",
    "        label = \"fresh\"\n",
    "\n",
    "    return expiry_date.strftime(\"%Y-%m-%d\"), label\n",
    "\n",
    "# ğŸ–¼ï¸ Loop over images and create labels\n",
    "rows = []\n",
    "for category in os.listdir(image_root):\n",
    "    category_path = os.path.join(image_root, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        for filename in os.listdir(category_path):\n",
    "            if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "                rel_path = os.path.join(category, filename)  # Relative path\n",
    "                expiry_date, label = generate_expiry_info()\n",
    "                rows.append([rel_path, expiry_date, label])\n",
    "\n",
    "# ğŸ’¾ Write to CSV\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"filename\", \"expiry_date\", \"freshness_class\"])\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"[âœ”] CSV created with {len(rows)} entries at: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff1701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "710127af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"synthetic_expiry_labels.csv\")\n",
    "label_map = {\"expired\": 0, \"expiring_soon\": 1, \"fresh\": 2}\n",
    "df[\"label\"] = df[\"freshness_class\"].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d96e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14eaa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroceryImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.loc[idx, \"filename\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.df.loc[idx, \"label\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66728fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data and encode classes\n",
    "df = pd.read_csv(\"synthetic_expiry_labels.csv\")\n",
    "label_map = {\"expired\": 0, \"expiring_soon\": 1, \"fresh\": 2}\n",
    "df[\"label\"] = df[\"freshness_class\"].map(label_map)\n",
    "\n",
    "# Train/test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86733c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class GroceryDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.loc[idx, \"filename\"])\n",
    "        label = self.df.loc[idx, \"label\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "# Dataloaders\n",
    "train_data = GroceryDataset(train_df, \"images\", transform)\n",
    "test_data = GroceryDataset(test_df, \"images\", transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feea66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExpiryCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpiryCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [B, 32, 64, 64]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [B, 64, 32, 32]\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # [B, 128, 16, 16]\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0e9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ExpiryCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a713309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define model, criterion, optimizer\n",
    "model = ExpiryCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# To track loss\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Average train loss\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    val_loss_list.append(avg_val_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(train_loss_list, label=\"Train Loss\")\n",
    "plt.plot(val_loss_list, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report & confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"expired\", \"expiring_soon\", \"fresh\"]))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"expired\", \"expiring_soon\", \"fresh\"], yticklabels=[\"expired\", \"expiring_soon\", \"fresh\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ef4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
